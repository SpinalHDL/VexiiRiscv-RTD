<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>LSU / Memory &mdash; VexiiRiscv  documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/theme_overrides.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/gh-fork-ribbon.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/vexiiriscv.css" type="text/css" />
    <link rel="shortcut icon" href="../../_static/logo3_32x32.png"/>
    <link rel="canonical" href="https://spinalhdl.github.io/VexiiRiscv-RTD/master/VexiiRiscv/Memory/index.html" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
        <script src="../../_static/clipboard.min.js"></script>
        <script src="../../_static/copybutton.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/wavedrom/2.6.8/skins/default.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/wavedrom/2.6.8/wavedrom.min.js"></script>
        <script src="../../_static/dialog.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Privileges" href="../Privileges/index.html" />
    <link rel="prev" title="Branch" href="../BranchPrediction/index.html" />
     
    <!-- source/_templates/layout.html -->
    
    
    

</head>

<body class="wy-body-for-nav">
     
    
    
    
    <div class="div-svg-github-corner github-corner-abs">
    <a href="https://github.com/SpinalHDL/VexiiRiscv-RTD/blob/master/source/VexiiRiscv/Memory/index.rst" class="github-corner github-fork-ribbon" aria-label="Edit on GitHub" data-ribbon="Edit on GitHub" title="Edit on GitHub">
      <object id="svg-github-corner" data="../../_static/github-corner-right.svg" class="svg-github-corner github-corner-abs" width="80" height="80"></object>
    </a>
    </div>
    
    
    

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            VexiiRiscv
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../Introduction/index.html">Introduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../Introduction/index.html#other-doc-media-talks">Other doc / media / talks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Introduction/index.html#technicalities">Technicalities</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Introduction/index.html#navigating-the-code">Navigating the code</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Introduction/index.html#about-risc-v">About RISC-V</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Introduction/index.html#glossary">Glossary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Introduction/index.html#about-vexriscv-not-vexiiriscv">About VexRiscv (not VexiiRiscv)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../HowToUse/index.html">How to use</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../HowToUse/index.html#environment-dependencies">Environment (Dependencies)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../HowToUse/index.html#docker-container">Docker Container</a></li>
<li class="toctree-l3"><a class="reference internal" href="../HowToUse/index.html#setup-dependencies">Setup dependencies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../HowToUse/index.html#repo-setup">Repo setup</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../HowToUse/index.html#generate-verilog">Generate verilog</a></li>
<li class="toctree-l2"><a class="reference internal" href="../HowToUse/index.html#run-a-simulation">Run a simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../HowToUse/index.html#synthesis">Synthesis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../HowToUse/index.html#other-resources">Other resources</a></li>
<li class="toctree-l2"><a class="reference internal" href="../HowToUse/index.html#using-intellij-idea">Using IntelliJ IDEA</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../HowToUse/index.html#setup">Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../HowToUse/index.html#known-issues">Known issues</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../HowToUse/index.html#using-konata">Using Konata</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../Tutorial/index.html">Self Contained Tutorial</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../Tutorial/index.html#tooling">Tooling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Tutorial/index.html#assembler">Assembler</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../Tutorial/index.html#looking-at-examples">Looking at examples</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Tutorial/index.html#write-the-assembler-code">Write the assembler code</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Tutorial/index.html#build-the-assembler-code">Build the assembler Code</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Tutorial/index.html#initial-run-error">Initial run (Error)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Tutorial/index.html#fixing-the-error">Fixing the Error</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Tutorial/index.html#the-assembler-hello-world">The assembler &quot;hello world&quot;</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Tutorial/index.html#looking-at-the-pipeline">Looking at the pipeline</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Tutorial/index.html#enabling-branch-prediction">Enabling branch prediction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Tutorial/index.html#looking-at-the-waveform">Looking at the waveform</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Tutorial/index.html#introducing-a-bug">Introducing a bug</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Tutorial/index.html#experimenting-with-privilege-levels">Experimenting with privilege levels</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Tutorial/index.html#connecting-with-openocd-to-the-simulation">Connecting with openocd to the simulation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../Tutorial/index.html#c-code-hello-world-literally">C code &quot;hello world&quot; (literally)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../Tutorial/index.html#write-the-c-code">Write the C code</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Tutorial/index.html#compiling-the-code">Compiling the Code</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Tutorial/index.html#compilation-error">Compilation error</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Tutorial/index.html#running-the-code">Running the code</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Tutorial/index.html#reading-a-csr">Reading a CSR</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../Docker/index.html">Ready made Docker environment</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../Docker/index.html#linux-and-macos-x">Linux and MacOS X</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Docker/index.html#windows">Windows</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Docker/index.html#generating-the-verilog">Generating the verilog</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Docker/index.html#running-a-simulation">Running a simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Docker/index.html#opening-the-traces-with-gtkwave">Opening the traces with GTKWave</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Docker/index.html#opening-the-traces-with-konata">Opening the traces with Konata</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Docker/index.html#opening-intellij-idea">Opening Intellij IDEA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Docker/index.html#shutting-down-the-container">Shutting down the Container</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Docker/index.html#using-the-build-environment">Using the build environment</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../Framework/index.html">Framework</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../Framework/index.html#tools-and-api">Tools and API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Framework/index.html#scala-spinalhdl">Scala / SpinalHDL</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Framework/index.html#plugin-fiber-retainer">Plugin / Fiber / Retainer</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../Framework/index.html#simple-all-in-one-example">Simple all-in-one example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Framework/index.html#negotiation-example">Negotiation example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../Framework/index.html#database">Database</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Framework/index.html#pipeline-api">Pipeline API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Framework/index.html#vexiiriscv-assumptions">VexiiRiscv assumptions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../Fetch/index.html">Fetch</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../Fetch/index.html#fetchpipelineplugin">FetchPipelinePlugin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Fetch/index.html#pcplugin">PcPlugin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Fetch/index.html#fetchcachelessplugin">FetchCachelessPlugin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Fetch/index.html#fetchl1plugin">FetchL1Plugin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Fetch/index.html#prefetchernextlineplugin">PrefetcherNextLinePlugin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Fetch/index.html#btbplugin">BtbPlugin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Fetch/index.html#gshareplugin">GSharePlugin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Fetch/index.html#historyplugin">HistoryPlugin</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../Decode/index.html">Decode</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../Decode/index.html#decodepipelineplugin">DecodePipelinePlugin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Decode/index.html#alignerplugin">AlignerPlugin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Decode/index.html#decoderplugin">DecoderPlugin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Decode/index.html#dispatchplugin">DispatchPlugin</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../Decode/index.html#architecture">Architecture</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Decode/index.html#elaboration">Elaboration</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../Execute/index.html">Execute</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../Execute/introduction.html">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Execute/plugins.html">Plugins</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../Execute/plugins.html#infrastructures">Infrastructures</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Execute/plugins.html#executepipelineplugin">ExecutePipelinePlugin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Execute/plugins.html#executelaneplugin">ExecuteLanePlugin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Execute/plugins.html#regfileplugin">RegFilePlugin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Execute/plugins.html#srcplugin">SrcPlugin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Execute/plugins.html#rsunsignedplugin">RsUnsignedPlugin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Execute/plugins.html#intformatplugin">IntFormatPlugin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Execute/plugins.html#writebackplugin">WriteBackPlugin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Execute/plugins.html#learnplugin">LearnPlugin</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Execute/plugins.html#instructions">Instructions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Execute/plugins.html#intaluplugin">IntAluPlugin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Execute/plugins.html#barrelshifterplugin">BarrelShifterPlugin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Execute/plugins.html#branchplugin">BranchPlugin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Execute/plugins.html#mulplugin">MulPlugin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Execute/plugins.html#divplugin">DivPlugin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Execute/plugins.html#lsucachelessplugin">LsuCachelessPlugin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Execute/plugins.html#lsuplugin">LsuPlugin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Execute/plugins.html#csraccessplugin">CsrAccessPlugin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Execute/plugins.html#envplugin">EnvPlugin</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../Execute/custom.html">Custom instruction</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../Execute/custom.html#simd-add">SIMD add</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Execute/custom.html#plugin-implementation">Plugin implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Execute/custom.html#vexiiriscv-generation">VexiiRiscv generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Execute/custom.html#software-test">Software test</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Execute/custom.html#simulation">Simulation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Execute/custom.html#conclusion">Conclusion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../Execute/fpu.html">FPU</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../Execute/fpu.html#plugins-architecture">Plugins architecture</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Execute/fpu.html#area-timings-options">Area / Timings options</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Execute/fpu.html#optimized-software">Optimized software</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../BranchPrediction/index.html">Branch</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../BranchPrediction/index.html#btbplugin">BtbPlugin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BranchPrediction/index.html#gshareplugin">GSharePlugin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BranchPrediction/index.html#decodeplugin">DecodePlugin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BranchPrediction/index.html#branchplugin">BranchPlugin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BranchPrediction/index.html#learnplugin">LearnPlugin</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">LSU / Memory</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#without-l1">Without L1</a></li>
<li class="toctree-l2"><a class="reference internal" href="#with-l1">With L1</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#prefetching">Prefetching</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#prefetchrptplugin">PrefetchRptPlugin</a></li>
<li class="toctree-l4"><a class="reference internal" href="#performance-measurements">performance measurements</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#hardware-memory-coherency">Hardware Memory coherency</a></li>
<li class="toctree-l3"><a class="reference internal" href="#atomic-memory-operation">Atomic Memory Operation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#load-reserve-store-conditional">Load Reserve / Store Conditional</a></li>
<li class="toctree-l3"><a class="reference internal" href="#memory-system">Memory system</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#why-tilelink">Why Tilelink</a></li>
<li class="toctree-l4"><a class="reference internal" href="#efficiency-cookbook">Efficiency cookbook</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../Privileges/index.html">Privileges</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../Privileges/index.html#csraccessplugin">CsrAccessPlugin</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../Privileges/index.html#privilegedplugin">PrivilegedPlugin</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Privileges/index.html#csrramplugin">CsrRamPlugin</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Privileges/index.html#trapplugin">TrapPlugin</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Privileges/index.html#performancecounterplugin">PerformanceCounterPlugin</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Privileges/index.html#envplugin">EnvPlugin</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Privileges/index.html#mmuplugin">MmuPlugin</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Privileges/index.html#pmpplugin">PmpPlugin</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../Debug/index.html">Debug support</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../Debug/index.html#architecture">Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Debug/index.html#embeddedriscvjtag">EmbeddedRiscvJtag</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../Performance/index.html">Performance / Area / FMax</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../Performance/index.html#tuning">Tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Performance/index.html#critical-paths-tool">Critical paths tool</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../Soc/index.html">SoC</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../Soc/microsoc.html">MicroSoc</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../Soc/microsoc.html#verilog-generation">Verilog generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Soc/microsoc.html#simulation-spinalsim-verilator">Simulation (SpinalSim / Verilator)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Soc/microsoc.html#compiling-and-running-c-c-with-cmake">Compiling and running C/C++ with CMake</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Soc/microsoc.html#adding-a-custom-peripheral">Adding a custom peripheral</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Soc/microsoc.html#exporting-an-apb3-bus-to-the-toplevel">Exporting an APB3 bus to the toplevel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Soc/microsoc.html#adding-a-custom-instruction">Adding a custom instruction</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../Soc/litex.html">Litex</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">VexiiRiscv</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">LSU / Memory</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/SpinalHDL/VexiiRiscv-RTD/blob/master/source/VexiiRiscv/Memory/index.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             <dialog id="doc-dialog-version" role="dialog" class="collapse-once" aria-modal="false" data-default-state="close" data-current-version="master" data-latest-version="master">
<p class="doc-version-warning-banner">
  <strong>
    
    You're reading an pre-release version of this documentation.<br/>
    For the latest stable release version, please have a look at <a href="index.html">master</a>.
    
  </strong>
  <div>
    <form>
      <button formmethod="dialog" type="submit" class="doc-dialog-dismiss" aria-label="close">Dismiss</button>
    </form>
  </div>
</p>
</dialog>




  <section id="lsu-memory">
<span id="lsu"></span><h1>LSU / Memory<a class="headerlink" href="#lsu-memory" title="Permalink to this heading"></a></h1>
<p>This chapter will handle things related to :</p>
<ul class="simple">
<li><p>Load / Store instructions</p></li>
<li><p>Atomic memory instructions</p></li>
<li><p>Load reserve / Store conditional instructions</p></li>
</ul>
<p>VexiiRiscv has currently 2 implementations for it:</p>
<ul class="simple">
<li><p>LsuCachelessPlugin for microcontrollers, which doesn't implement any cache</p></li>
<li><p>LsuPlugin / LsuL1Plugin which can work together to implement load and store through an L1 cache</p></li>
</ul>
<section id="without-l1">
<h2>Without L1<a class="headerlink" href="#without-l1" title="Permalink to this heading"></a></h2>
<p>Implemented by the LsuCachelessPlugin, it should be noted that to
reach good frequencies on FPGA SoC, forking the memory request at
execute stage 1 seems to provide the best results (instead of execute stage 0),
as it relax the AGU timings as well as the PMA (Physical Memory Attributes) checks.</p>
<img alt="../../_images/lsu_nol1.png" src="../../_images/lsu_nol1.png" />
</section>
<section id="with-l1">
<h2>With L1<a class="headerlink" href="#with-l1" title="Permalink to this heading"></a></h2>
<p>This configuration supports :</p>
<ul class="simple">
<li><p>N ways (limited to 4 KB per way if the MMU is enabled)</p></li>
<li><p>Non-blocking design, able to handle multiple cache line refill and writeback</p></li>
<li><p>Hardware and software prefetching (RPT design)</p></li>
</ul>
<img alt="../../_images/lsu_l1.png" src="../../_images/lsu_l1.png" />
<p>This LSU implementation is partitioned between 2 plugins :</p>
<p>The LsuPlugin :</p>
<ul class="simple">
<li><p>Implement AGU (Address Generation Unit)</p></li>
<li><p>Arbitrate all the different sources of memory request (AGU, store queue, prefetch, MMU refill)</p></li>
<li><p>Provide the memory request to the LsuL1Plugin</p></li>
<li><p>Bind the MMU translation port</p></li>
<li><p>Handle the exceptions and hazard recovery</p></li>
<li><p>Handle the atomic operations (ALU + locking of the given cache line)</p></li>
<li><p>Handle IO memory accesses</p></li>
<li><p>Implement the store queue to handle store misses in a non-blocking way</p></li>
<li><p>Feed the hardware prefetcher with load/store execution traces</p></li>
</ul>
<p>The LsuL1Plugin :</p>
<ul class="simple">
<li><p>Implement the L1 tags and data storage</p></li>
<li><p>Implement the cache line refill and writeback slots (non-blocking)</p></li>
<li><p>Implement the store to load bypasses</p></li>
<li><p>Implement the memory coherency interface</p></li>
<li><p>Is integrated in the execute pipeline (to save area and improve timings)</p></li>
</ul>
<p>For multiple reasons (ease of implementation, FMax, hardware usage), VexiiRiscv LSU can hit hazards situations :</p>
<ul class="simple">
<li><p>Cache miss, MMU miss</p></li>
<li><p>Refill / Writeback aliasing (4KB)</p></li>
<li><p>Unread data bank during load (ex : load during data bank refill)</p></li>
<li><p>Load which hit the store queue</p></li>
<li><p>Store miss while the store queue is full</p></li>
<li><p>...</p></li>
</ul>
<p>In those situation, the LsuPlugin will trigger an &quot;hardware trap&quot;
which will flush the pipeline and reschedule the failed instruction to the fetch unit.</p>
<p>Here is a set of options which can be used :</p>
<table class="docutils align-default" id="id1">
<caption><span class="caption-text">Generation parameters</span><a class="headerlink" href="#id1" title="Permalink to this table"></a></caption>
<colgroup>
<col style="width: 30%" />
<col style="width: 70%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Parameter</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>--lsu-l1</p></td>
<td><p>Enable the L1 D$</p></td>
</tr>
<tr class="row-odd"><td><p>--lsu-l1-ways=X</p></td>
<td><p>Specify the number of ways  for the L1 D$ (how many direct mapped caches in parallel), default=1</p></td>
</tr>
<tr class="row-even"><td><p>--lsu-l1-sets=X</p></td>
<td><p>Specify the number of sets for the L1 D$ (how many line of cache per way), default=64</p></td>
</tr>
<tr class="row-odd"><td><p>--lsu-l1-mem-data-width-min=X</p></td>
<td><p>Set a lower bound for the L1 D$ data width</p></td>
</tr>
<tr class="row-even"><td><p>--lsu-software-prefetch</p></td>
<td><p>Enable RISC-V CMO for software prefetching in the D$</p></td>
</tr>
<tr class="row-odd"><td><p>--lsu-hardware-prefetch rpt</p></td>
<td><p>Enable the L1 D$ hardware prefetcher (based on RPT)</p></td>
</tr>
<tr class="row-even"><td><p>--lsu-l1-store-buffer-ops=X</p></td>
<td><p>Specify how many store miss can be pushed in the store buffer (disabled/0 by default)</p></td>
</tr>
<tr class="row-odd"><td><p>--lsu-l1-store-buffer-slots=X</p></td>
<td><p>Specify how many block of memory can be targeted by the store buffer (disabled/0 by default)</p></td>
</tr>
<tr class="row-even"><td><p>--lsu-l1-refill-count=X</p></td>
<td><p>Specify how many cache line refill the L1 D$ can handle at the same time, default=1</p></td>
</tr>
<tr class="row-odd"><td><p>--lsu-l1-writeback-count=X</p></td>
<td><p>Specify how many cache line writeback the L1 D$ can handle at the same time, default=1</p></td>
</tr>
</tbody>
</table>
<p>To improve the performances, consider first increasing the number of cache ways to 4.</p>
<p>The store buffer will help a lot with the store bandwidth by allowing the CPU to not be blocked by every store miss.
The hardware prefetcher will help with both store/load bandwidth (but if the store buffer is already enabled, it will not
really increase the store bandwidth).</p>
<p>For the hardware prefetcher to stretch its leg, consider using 4 refill/writeback slots. This will also help the store buffer.</p>
<section id="prefetching">
<h3>Prefetching<a class="headerlink" href="#prefetching" title="Permalink to this heading"></a></h3>
<p>Currently there is two implementation of prefetching</p>
<ul class="simple">
<li><p>PrefetchNextLinePlugin : As its name indicates, on each cache miss it will prefetch the next cache line</p></li>
<li><p>PrefetchRptPlugin : Enable prefetching for instruction which have a constant stride between accesses</p></li>
</ul>
<section id="prefetchrptplugin">
<h4>PrefetchRptPlugin<a class="headerlink" href="#prefetchrptplugin" title="Permalink to this heading"></a></h4>
<p>This prefetcher is capable of recognizing instructions which have a constant stride between their
own previous accesses in order to prefetch multiple strides ahead.</p>
<ul class="simple">
<li><p>Will learn memory accesses patterns from the LsuPlugin traces</p></li>
<li><p>Patterns need to have a constant stride in order to be recognized</p></li>
<li><p>By default, it can keep track of up to 128 instructions access pattern (1 way * 128 sets, pc indexed)</p></li>
</ul>
<img alt="../../_images/lsu_prefetch.png" src="../../_images/lsu_prefetch.png" />
<p>This can improve performance dramatically (for some use cases).
For instance, on a 100 MHz SoC in a FPGA, equipped of a 16x800 MT/s DDR3,
the load bandwidth went from 112 MB/s to 449  MB/s. (sequential load)</p>
<p>Here is a description of the table fields :</p>
<p>&quot;Tag&quot; : Allows to get a better idea if the given instruction (PC) is the one owning
the table entry by comparing more PC's MSB bits.
An entry is &quot;owned&quot; by an instruction if its tag match the given instruction PC's msb bits.</p>
<p>&quot;Address&quot; : Previous virtual address generated by the instruction</p>
<p>&quot;stride&quot; : Number of bytes expected between memory accesses</p>
<p>&quot;Score&quot; : Allows to know if the given entry is useful or not. Each time
the instruction is keeping the same stride, the score increase, else it decrease.
If another instruction (with another tag) want to use an entry,
the score field has to be low enough.</p>
<p>&quot;Advance&quot; : Allows to keep track how far the prefetching for the given
instruction already went. This field is cleared when a entry switch
to a new instruction</p>
<p>&quot;Missed&quot; : This field was added in order to reduce the spam of
redundant prefetch request which were happening for load/store intensive code.
For instance, for a deeply unrolled memory clear loop will generate (x16),
as each store instruction PC will be tracked individually,
and as each execution of a given instruction will stride over a full cache line,
this will generate one hardware prefetch request on each store instruction every
time, spamming the LSU pipeline with redundant requests
and reducing overall performances.</p>
<p>This &quot;missed&quot; field works as following :</p>
<ul class="simple">
<li><p>It is cleared when a stride disruption happens (ex new memcopy execution)</p></li>
<li><p>It is set on cache miss (set win over clear)</p></li>
<li><p>An instruction will only trigger a prefetch if it miss or
if its &quot;missed&quot; field is already set.</p></li>
</ul>
<p>For example, in a hardware simulation test
(RV64, 20 cycles memory latency, 16xload loop), this addition increased
the memory read memory bandwidth from 3.6 bytes/cycle to 6.8 bytes per cycle.</p>
<p>Note that if you want to take full advantage of this prefetcher, you need to
have enough hardware refill/writeback slots in the LsuL1Plugin.</p>
<p>Also, prefetch which fail (ex : because of hazards in L1) aren't replayed.</p>
<p>The prefetcher can be turned off by setting the CSR 0x7FF bit 1.</p>
</section>
<section id="performance-measurements">
<h4>performance measurements<a class="headerlink" href="#performance-measurements" title="Permalink to this heading"></a></h4>
<p>Here are a few performance gain measurements done on litex with a :</p>
<ul class="simple">
<li><p>quad-core RV64GC running at 200 MHz</p></li>
<li><p>16 KB L1 cache for each core</p></li>
<li><p>512 KB of l2 cache shared (128 bits data bus)</p></li>
<li><p>4 refill slots + 4 writeback slots + 32 entry store queue + 4 slots store queue</p></li>
</ul>
<table class="docutils align-default" id="id2">
<caption><span class="caption-text">Prefetch performance</span><a class="headerlink" href="#id2" title="Permalink to this table"></a></caption>
<colgroup>
<col style="width: 40%" />
<col style="width: 30%" />
<col style="width: 30%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Test</p></th>
<th class="head"><p>No prefetch</p></th>
<th class="head"><p>RPT prefetch</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Litex bios read speed</p></td>
<td><p>204.2MiB/s</p></td>
<td><p>790.9MiB/s</p></td>
</tr>
<tr class="row-odd"><td><p>Litex bios write speed</p></td>
<td><p>559.2MiB/s</p></td>
<td><p>576.8MiB/s</p></td>
</tr>
<tr class="row-even"><td><p>iperf3 RX</p></td>
<td><p>617 Mbits/sec</p></td>
<td><p>766 Mbits/sec</p></td>
</tr>
<tr class="row-odd"><td><p>iperf3 TX</p></td>
<td><p>623 Mbits/sec</p></td>
<td><p>623 Mbits/sec</p></td>
</tr>
<tr class="row-even"><td><p>chocolate-doom -1 demo1.lmp</p></td>
<td><p>43.1 fps</p></td>
<td><p>50.2 fps</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="hardware-memory-coherency">
<h3>Hardware Memory coherency<a class="headerlink" href="#hardware-memory-coherency" title="Permalink to this heading"></a></h3>
<p>Hardware memory coherency, is the feature which allows multiple memory agents (ex : CPU, DMA, ...)
to work on the same memory locations and notify each others when they change their contents.
Without it, the CPU software would have to manually flush/invalidate their L1 caches to keep things in sync.</p>
<p>There is mostly 2 kinds of hardware memory coherency architecture :</p>
<ul class="simple">
<li><p>By invalidation : When a CPU/DMA write some memory, it notifies the other CPU caches that they should invalidate any
old copy that they have of the written memory locations. This is generally used for write-through L1 caches.
This isn't what VexiiRiscv implements.</p></li>
<li><p>By permission : Memory blocks copies (typically 64 aligned bytes blocks which resides in L1 cache lines) can have multiple states.
Some of which provide read only accesses, while others provide read/write accesses. This is generally used in write-back L1 caches,
and this is what VexiiRiscv uses.</p></li>
</ul>
<p>In VexiiRiscv, the hardware memory coherency (L1) with other memory agents (CPU, DMA, L2, ..) is supported though a MESI implementation which can be bridged to a tilelink memory bus.</p>
<p>MESI is an standard acronym for every possible state that a copy of a memory block can have in the caches :</p>
<ul class="simple">
<li><p>I : Invalid, meaning that there is no copy of that memory block</p></li>
<li><p>S : Shared, meaning that the cache has a read only copy of the memory block, and that other caches may also have a copy. This state is sometime named : Shared/Clean</p></li>
<li><p>E : Exclusive, meaning that the cache has a read/writable copy of the memory block which is still in a clean state (unmodified, no writeback required),
and that no other cache has a copy of the block. This state is sometime named : Unique/Clean</p></li>
<li><p>M : Modified, meaning that the cache line exclusive, but has been modified, and so, require a writeback later on. This state is sometime named : Unique/Dirty</p></li>
</ul>
<p>Here is a diagram which shows an example of memory block copy exchanges between 2 CPUs :</p>
<img alt="../../_images/tilelink_coherency.png" src="../../_images/tilelink_coherency.png" />
<p>The VexiiRiscv L1 cache interconnect interface is kinda close to what Tilelink specifies and can easily be bridged to Tilelink.
The main difference is that probe requests can fail (need to be replayed), and that probes which which hit will then go through the writeback interface.
Here is the hardware interfaces :</p>
<ul class="simple">
<li><p>read_cmd : To send memory block acquire requests (invalid/shared -&gt; shared/exclusive)</p></li>
<li><p>read_rsp : For responses of the above requests</p></li>
<li><p>read_ack : To send acquire requests completion</p></li>
<li><p>write_cmd : To send release a memory block permission (shared/exclusive -&gt; invalid)</p></li>
<li><p>write_rsp : For responses of the above requests</p></li>
<li><p>probe_cmd : To receive probe requests (toInvalid/toShared/toUnique)</p></li>
<li><p>probe_rsp : to send responses from the above requests (isInvalid/isShared/isUnique).
When data need to be written back, it will be done through the write_cmd channel.</p></li>
</ul>
</section>
<section id="atomic-memory-operation">
<h3>Atomic Memory Operation<a class="headerlink" href="#atomic-memory-operation" title="Permalink to this heading"></a></h3>
<p>AMO stand for Atomic Memory Operations (ex : atomic swap, atomic add, ...)</p>
<p>Typicaly, an AMO execute the following pseudo code (ex : atomic add).</p>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"> </span><span class="nf">amoadd</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">address</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">add_alu</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="c1">// Atomic section</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">read_value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">address</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span><span class="w">           </span><span class="c1">// Read memory</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">alu_value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">read_value</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">add_alue</span><span class="p">;</span><span class="w"> </span><span class="c1">// Process data</span>
<span class="w">    </span><span class="n">address</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">alu_value</span><span class="p">;</span><span class="w">                </span><span class="c1">// Write memory</span>
<span class="w">    </span><span class="c1">// End of atomic section, write read_value to the register file</span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>When memory coherency is enabled, here is how AMO instruction are implemented in VexiiRiscv :</p>
<ul class="simple">
<li><p>AMO starts like a regular memory Load</p></li>
<li><p>Once it reach the last stage of the cache (execute stage 2), if there is a cache miss, or the cache line isn't in a exclusive state, the instruction fail and is retried.</p></li>
<li><p>If the above condition is successfull, the LSU will lock the given cache line for a few cycles, preventing any writeback.
The combination of the cache line locking and exclusive state ensure that no other agent can modify the memory block while the atomic operation is done.</p></li>
<li><p>While the cache line is locked, the atomic ALU will process the readed value, then write the result into the cache and release the cache line lock.</p></li>
</ul>
</section>
<section id="load-reserve-store-conditional">
<h3>Load Reserve / Store Conditional<a class="headerlink" href="#load-reserve-store-conditional" title="Permalink to this heading"></a></h3>
<p>LR stand for Load Reserve, SC stand for Store Conditional.
Those two instruction work in pairs and allows to implement atomic memory operations quite differently from the AMO instruction.</p>
<p>The idea is:</p>
<ul class="simple">
<li><p>First, the CPU attempts to load and reserve a given portion of memory via the LR instruction.</p></li>
<li><p>Then the CPU process the loaded data using regular integer instruction (it has a limited time to do it and a few other restrictions)</p></li>
<li><p>Finaly, the CPU store a modified value using the SC instruction.</p></li>
</ul>
<p>The trick is that the store instruction may fail, and will fail in a few conditions :</p>
<ul class="simple">
<li><p>If another memory agent wrote the reserved memory location</p></li>
<li><p>The CPU was too slow to process the loaded data</p></li>
<li><p>...</p></li>
</ul>
<p>So an AMOADD could be emulated via :</p>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"> </span><span class="nf">amoadd</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">address</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">add_alu</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="k">while</span><span class="p">(</span><span class="mi">1</span><span class="p">){</span><span class="w"></span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">read_value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">LR</span><span class="p">(</span><span class="n">address</span><span class="p">);</span><span class="w">                  </span><span class="c1">// Load Reserve</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">alu_value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">read_value</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">add_alue</span><span class="p">;</span><span class="w">         </span><span class="c1">// Process data</span>
<span class="w">        </span><span class="k">if</span><span class="p">(</span><span class="n">SC</span><span class="p">(</span><span class="n">address</span><span class="p">,</span><span class="w"> </span><span class="n">alu_value</span><span class="p">)</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">SUCCESS</span><span class="p">)</span><span class="w"> </span><span class="k">break</span><span class="p">;</span><span class="w">   </span><span class="c1">// Store Conditional</span>
<span class="w">    </span><span class="p">}</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>In VexiiRiscv, the LR / SC instruction are implemented the following way :</p>
<ul class="simple">
<li><p>LR mostly behave like a regular memory load, but will require the cache line to be in a exclusive state to successed.
Also, the cache line will be locked for a 32 cycles to ensure other memory agent would not remove the cache line via probes systematicaly.</p></li>
<li><p>SC mostly behave like a regular memory store, but will check that the lock is still active, else it will skip the memory store and notify the CPU of the failure</p></li>
</ul>
<p>Also, note that if one CPU pull a memory value using LR in a for loop (this is done in a few place in the linux kernel, ex : spinlock), it shouldn't be able to refresh the lock,
as this would completely prevent another CPU from acquiring the memory block. So, for this reason, VexiiRiscv does not set the reservation on a LR,
but instead toggle the reservation status.</p>
</section>
<section id="memory-system">
<h3>Memory system<a class="headerlink" href="#memory-system" title="Permalink to this heading"></a></h3>
<p>Currently, VexiiRiscv can be used with the Tilelink memory interconnect from SpinalHDL and Chipyard (<a class="reference external" href="https://chipyard.readthedocs.io/en/latest/Generators/VexiiRiscv.html">https://chipyard.readthedocs.io/en/latest/Generators/VexiiRiscv.html</a>).</p>
<section id="why-tilelink">
<h4>Why Tilelink<a class="headerlink" href="#why-tilelink" title="Permalink to this heading"></a></h4>
<p>So, why using Tilelink, while most of the FPGA industry is using AXI4 ? Here are some issues / complexities that AXI4 bring with it.
(Dolu1990 opinions, with the perspective of using it in FPGA, with limited manpower, don't see this as an absolute truth)</p>
<ul class="simple">
<li><p>The AXI4 memory ordering, while allowing CPU/DMA to get preserved ordering between transactions with the same ID,
is creating complexities and bottlenecks in the memory system. Typically in the interconnect decoders
to avoid dead-locks, but even more in L2 caches and DRAM controllers which ideally would handle every request out of order.
Tilelink instead specify that the CPU/DMAs shouldn't assume any memory ordering between inflight transactions.</p></li>
<li><p>AXI4 specifies that memory read response channel can interleave between multiple ongoing bursts.
While this can be use full for very large burst (which in itself is a bad idea, see next chapter),
this can lead to big area overhead for memory bridges, especially with width adapters.
Tilelink doesn't allows this behavior.</p></li>
<li><p>AXI4 splits write address from write data, which add additional synchronizations points in the interconnect decoders/arbiters and peripherals (bad for timings)
as well as potentially decrease performances when integrating multiple AXI4 modules which do not use similar address/data timings.</p></li>
<li><p>AXI4 isn't great for low latency memory interconnects, mostly because of the previous point.</p></li>
<li><p>AXI4 splits read and write channels (ar r / aw w b), which mostly double the area cost of address decoding/routing for DMA and non-coherent CPUs.</p></li>
<li><p>AXI4 specifies a few &quot;low values&quot; features which increase complexity and area (ex: WRAP/FIXED bursts, unaligned memory accesses).</p></li>
</ul>
</section>
<section id="efficiency-cookbook">
<h4>Efficiency cookbook<a class="headerlink" href="#efficiency-cookbook" title="Permalink to this heading"></a></h4>
<p>Here are a set of design guideline to keep a memory system lean and efficient (don't see this as an absolute truth) :</p>
<ul class="simple">
<li><p>Memory blocks are 64 aligned bytes long : DDR3/4/5 modules are tuned to provides native 64 bytes burst accesses (not less, not more).
In particular, with DDR5 modules, they doubled the module burst size (to 16 beats), but in order to preserve 64 bytes burst accesses,
they divided the 64 bits physical data width between two independent channels.
CPU cache lines, L2 and L3 designs follow that 64 bytes block &quot;rule&quot; as well.
Their coherency dictionary will be designed to handle 64 bytes memory blocks too.
AMBA 5 CHI enforce 64 bytes cache lines, and doesn't support memory transfers with more than 64 bytes.</p></li>
<li><p>DMA should not reuse the same transaction ID (axi/tilelink) between multiple inflight transactions and should not expect any ordering between inflight transactions. That keep them highly portable and relax the memory system.</p></li>
<li><p>DMA should access up to 64 aligned bytes per burst, this should be enough to reach peak bandwidth. No need for 4KB Rambo bursts.
Asking a system to support bursts bigger than 64 aligned bytes can lead to extra cost, as it create new ordering constraints between the memory block of the burst.
For instance in a L2 cache it can lead to implementation of a reorder buffer to deal between transaction which hit/miss the cache. Adding extra complexity/area/timings to deal with.
Additionally, big burst can create high latency spike for other agents (CPU/DMA).</p></li>
<li><p>DMA should only do burst aligned memory accesses (to keep them easily portable to Tilelink)</p></li>
<li><p>It is fine for DMA to over fetch (let's say you need 48 bytes, but access aligned 64 bytes instead),
as long as the bulk of the memory bandwidth is not doing it.</p></li>
<li><p>DMA should avoid doing multiple accesses in a 64 byte block if possible, and instead use a single access.
This can preserve the DRAM controller bandwidth (see DDR3/4/5 comments above),
but also, L2/L3 cache designs may block any additional memory request targeting a memory block which is already under operation.</p></li>
<li><p>When a DMA start a write burst, it has to complete as fast as possible. The reason is that the interconnect can lock itself on your burst until you finish it.</p></li>
<li><p>When a DMA start a read burst, it should avoid putting backpressure on the read responses. The reason is that the interconnect can lock itself on your burst until you finish it.</p></li>
</ul>
</section>
</section>
</section>
</section>

    <script type="text/javascript">
        function init() {
            WaveDrom.ProcessAll();
        }
        window.onload = init;
    </script>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../BranchPrediction/index.html" class="btn btn-neutral float-left" title="Branch" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../Privileges/index.html" class="btn btn-neutral float-right" title="Privileges" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023 - 2025, VexiiRiscv.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
  
     
    <!-- source/_templates/footer.html -->
    
    <div class="doc-footer-current-version"><p>
    Version: master git~6c6a1e5 2025-01-07
    </p></div>
    


</footer>
        </div>
      </div>
    </section>
  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book"> Other Versions</span>
    v: master
    <span class="fa fa-caret-down"></span>
  </span>
  <div class="rst-other-versions">
    <dl>
       <dt>Languages</dt>
       <dd class="rtd-current-item">
         <a href="#">en</a>
       </dd>
    </dl>
    <dl>
      <dt>Branches</dt>
      <dd><a href="index.html">master</a></dd>
    </dl>
    <dl>
      <dt>Downloads</dt>
      <dd><a href="../../artefacts/VexiiRiscv_docs-master.">HTML</a></dd>
      <dd><a href="../../artefacts/VexiiRiscv_docs-master-SingleHTML.zip">SingleHTML</a></dd>
      <dd><a href="../../artefacts/VexiiRiscv_docs-master.pdf">PDF</a></dd>
    </dl>
  </div>
</div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>